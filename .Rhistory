knitr::opts_chunk$set(
fig.align = "center",
fig.width = 6,
fig.height = 4,
out.width = "80%",
echo = TRUE,               # Show code by default
warning = FALSE,           # Suppress warnings
message = FALSE            # Suppress messages
)
options(digits = 3, width = 90)
DotProbeModel.ChenModel <- readRDS("DotProbeModel.ChenModel.RDS")
DotProbeModel.ChenModel <- readRDS("~/Documents/CogPsychRes/posts/DotProbeReliability/DotProbeModel.ChenModel.RDS")
library(tidybayes)
newdata <- tidyr::expand_grid(
id = unique(Study1_fs$id),
split = c("1", "2"),
condition = c("TIC", "TC")
)
newdata <- tidyr::expand_grid(
id = unique(DotProbeModel.ChenModel$data$id),
split = c("1", "2"),
condition = c("TIC", "TC")
)
pred <- add_epred_rvars(
DotProbeModel.ChenModel,
newdata = newdata,
re_formula = NULL
) %>%
mutate(condition = interaction(split, condition, sep = "_"))
library(tidyverse)
pred <- add_epred_rvars(
DotProbeModel.ChenModel,
newdata = newdata,
re_formula = NULL
) %>%
mutate(condition = interaction(split, condition, sep = "_"))
diff_scores <- pred %>%
select(id, condition, .epred) %>%
pivot_wider(names_from = condition, values_from = .epred) %>%
mutate(
Effect_1 = `1_TIC` - `1_TC`,  # Split 1 effect (ms)
Effect_2 = `2_TIC` - `2_TC`   # Split 2 effect (ms)
)
cor_results <-
data.frame(correlation =  with(diff_scores, {
rdo(cor(Effect_1, Effect_2))})) %>%
mutate(spearman_brown = (2 * correlation) / (1 + correlation))
library(posterior)
cor_results <-
data.frame(correlation =  with(diff_scores, {
rdo(cor(Effect_1, Effect_2))})) %>%
mutate(spearman_brown = (2 * correlation) / (1 + correlation))
post_corrs_long <- cor_results %>%
pivot_longer(
cols      = c(correlation, spearman_brown),
names_to  = "cor_type",
values_to = "cor_value"
)
# Create the data frame using your method:
df <- post_corrs_long %>%
group_by(cor_type) %>%
summarize(x = rvar(cor_value))
# Compute median values (the rvar supports summary functions)
median_values <- df %>%
group_by(cor_type) %>%
summarize(median_val = median(x))
# Build the plot
p <- ggplot(df, aes(xdist = x, y = cor_type, fill = cor_type)) +
stat_slab(
aes(fill_ramp = after_stat(level)),
.width = c(0.5, 0.8, 0.9, 0.95, 0.99),
point_interval = median_hdci,    # Use the HDI rather than the default quantile interval
slab_color = "grey30",
slab_size = 0.75
) +
scale_fill_manual(values = c("#E64B35B2", "#4DBBD5B2")) +
guides(fill_ramp = "none", fill = "none") +
# Spike for the median (dotted line)
stat_spike(
aes(linetype = "Median", color = "Median"),
at = c(median),
show.legend = TRUE
) +
# Spike for the 95% HDI (solid line)
stat_spike(
aes(linetype = "95% HDI", color = "95% HDI"),
at = function(x) hdci(x, .width = 0.95),
show.legend = TRUE
) +
# Spike for the MAP estimate is kept for future use, but commented out:
# stat_spike(
#   aes(linetype = "MAP estimate", color = "MAP estimate"),
#   at = function(x) bayestestR::map_estimate(x)[[2]],
#   show.legend = TRUE
# ) +
scale_thickness_shared() +
# Manual scales for the spike lines (using black for both)
scale_linetype_manual(
name = "Summary Statistic",
values = c("Median" = "longdash", "95% HDI" = "solid")
) +
scale_color_manual(
name = "Summary Statistic",
values = c("Median" = "#8494FF", "95% HDI" = "#000000")
) +
labs(
title = "Split-Half Reliability Estimates",
subtitle = "Comparing Pearson correlation and Spearman-Brown corrected reliability",
x = "Reliability Coefficient",
y = "",
caption = "Dashed line: median; Solid line: 95% Highest Density Interval (HDI).\nFill shades represent the 50%, 80%, 90%, 95% and 99% credible intervals."
) +
scale_y_discrete(labels = c("Pearson\nCorrelation", "Spearman-Brown\nCorrected")) +
theme_minimal() +
theme(
plot.title    = element_text(face = "bold", size = 16, margin = margin(b = 10)),
plot.subtitle = element_text(color = "grey40", size = 12, margin = margin(b = 20)),
axis.title.x  = element_text(size = 12, margin = margin(t = 10)),
axis.text     = element_text(size = 11, color = "grey30"),
axis.text.y   = element_text(hjust = 0.5), # This centers the y-axis text
panel.grid.minor = element_blank(),
panel.grid.major.y = element_blank(),
plot.caption  = element_text(hjust = 0.5)
) +
xlim(0, 1)
library(ggdist)
# Build the plot
p <- ggplot(df, aes(xdist = x, y = cor_type, fill = cor_type)) +
stat_slab(
aes(fill_ramp = after_stat(level)),
.width = c(0.5, 0.8, 0.9, 0.95, 0.99),
point_interval = median_hdci,    # Use the HDI rather than the default quantile interval
slab_color = "grey30",
slab_size = 0.75
) +
scale_fill_manual(values = c("#E64B35B2", "#4DBBD5B2")) +
guides(fill_ramp = "none", fill = "none") +
# Spike for the median (dotted line)
stat_spike(
aes(linetype = "Median", color = "Median"),
at = c(median),
show.legend = TRUE
) +
# Spike for the 95% HDI (solid line)
stat_spike(
aes(linetype = "95% HDI", color = "95% HDI"),
at = function(x) hdci(x, .width = 0.95),
show.legend = TRUE
) +
# Spike for the MAP estimate is kept for future use, but commented out:
# stat_spike(
#   aes(linetype = "MAP estimate", color = "MAP estimate"),
#   at = function(x) bayestestR::map_estimate(x)[[2]],
#   show.legend = TRUE
# ) +
scale_thickness_shared() +
# Manual scales for the spike lines (using black for both)
scale_linetype_manual(
name = "Summary Statistic",
values = c("Median" = "longdash", "95% HDI" = "solid")
) +
scale_color_manual(
name = "Summary Statistic",
values = c("Median" = "#8494FF", "95% HDI" = "#000000")
) +
labs(
title = "Split-Half Reliability Estimates",
subtitle = "Comparing Pearson correlation and Spearman-Brown corrected reliability",
x = "Reliability Coefficient",
y = "",
caption = "Dashed line: median; Solid line: 95% Highest Density Interval (HDI).\nFill shades represent the 50%, 80%, 90%, 95% and 99% credible intervals."
) +
scale_y_discrete(labels = c("Pearson\nCorrelation", "Spearman-Brown\nCorrected")) +
theme_minimal() +
theme(
plot.title    = element_text(face = "bold", size = 16, margin = margin(b = 10)),
plot.subtitle = element_text(color = "grey40", size = 12, margin = margin(b = 20)),
axis.title.x  = element_text(size = 12, margin = margin(t = 10)),
axis.text     = element_text(size = 11, color = "grey30"),
axis.text.y   = element_text(hjust = 0.5), # This centers the y-axis text
panel.grid.minor = element_blank(),
panel.grid.major.y = element_blank(),
plot.caption  = element_text(hjust = 0.5)
) +
xlim(0, 1)
# Add geom_label for the median values.
(p + geom_label(
data = median_values,
mapping = aes(x = median_val, y = cor_type, label = sprintf("%.2f", median_val)),
inherit.aes = FALSE,  # Do not inherit the global aesthetics (including xdist)
color = "black",
fill = "white",
size = 3
))
list.files(all.files = T)
list.files(all.files = T,recursive = T)
setwd("~/Documents/CogPsychRes")
list.files(all.files = T, recursive = T)
rm about.qmd               # Remove about page
setwd("~/Documents/CogPsychRes")
knitr::opts_chunk$set(
fig.align = "center",
fig.width = 6,
fig.height = 4,
out.width = "80%",
echo = TRUE,               # Show code by default
warning = FALSE,           # Suppress warnings
message = FALSE            # Suppress messages
)
options(digits = 3, width = 90)
sessioninfo::session_info()
install.packages("sessioninfo")
sessioninfo::session_info()
setwd("~/Documents/CogPsychRes")
list.files(all.files = T, recursive = T)
git init
setwd("~/Documents/CogPsychRes")
list.files(all.files = T, recursive = T)
list.files(all.files = T, recursive = T)
setwd("~/Documents/CogPsychRes")
list.files(all.files = T, recursive = T)
nfp_PBy4rH82WdCDjHnJKtw2LTVJmAvHz7Zg345a
knitr::opts_chunk$set(
fig.align = "center",
fig.width = 6,
fig.height = 4,
out.width = "80%",
echo = TRUE,               # Show code by default
warning = FALSE,           # Suppress warnings
message = FALSE            # Suppress messages
)
options(digits = 3, width = 90)
library(tidyverse)
`%ni%` <- Negate(`%in%`)
Study_1 <- readr::read_csv("openData_study1_trials_102823.csv")
s1.all.outcomes <- readr::read_csv("openData_study1_outcomes_102823.csv")
# Exclude participants with <60% accuracy or median RT <300 ms
s1.excluded.id <- s1.all.outcomes %>%
filter(all_accuracy < 0.6 | all_medRTc < 300) %>%
pull(id)
Study1_fs <- Study_1 %>%
filter(id %ni% s1.excluded.id,
condition != "practice",
resp_type != "timeout") %>%
filter(test_id %in% c(1:3, 19:21),
resp_type == "mouse") %>%
mutate(
RT = as.numeric(rt) / 1000,  # Convert RT to seconds
accuracy = as.numeric(correct),
trial.all.type = row_number(),
split = as.factor(ifelse(trial.all.type %% 2 == 1, 1, 2)),
condition = case_when(
condition == 1 ~ "TC",
condition == 2 ~ "TIC",
condition == 3 ~ "TT",
condition == 4 ~ "NN"
)
) %>%
filter(RT > 0.25, RT < 3.5, accuracy == 1, condition %in% c("TC", "TIC")) %>%
group_by(id, condition) %>%
mutate(Outlier = c(datawizard::standardize(RT, robust = TRUE))) %>%
ungroup() %>%
filter(abs(Outlier) < 3.29)
library(tidyverse)
`%ni%` <- Negate(`%in%`)
Study_1 <- readr::read_csv("openData_study1_trials_102823.csv")
